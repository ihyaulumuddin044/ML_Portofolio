{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMTx5IdQptZUAZuW+aDb8ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihyaulumuddin044/ML_Portofolio/blob/main/sentimen_analysis/sentimen_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YISJcLMJ91w-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('twitter_training_updeted.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iydQPhx8-HwA",
        "outputId": "6838cce6-31b5-492a-d7f1-5317292345a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id         game sentiment  \\\n",
              "0  2401  Borderlands  Positive   \n",
              "1  2401  Borderlands  Positive   \n",
              "2  2401  Borderlands  Positive   \n",
              "3  2401  Borderlands  Positive   \n",
              "4  2401  Borderlands  Positive   \n",
              "\n",
              "                                                text  \n",
              "0  I am coming to the borders and I will kill you...  \n",
              "1  im getting on borderlands and i will kill you ...  \n",
              "2  im coming on borderlands and i will murder you...  \n",
              "3  im getting on borderlands 2 and i will murder ...  \n",
              "4  im getting into borderlands and i can murder y...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bbf2f81-4c20-44aa-a04d-1b8ad6103889\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>game</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bbf2f81-4c20-44aa-a04d-1b8ad6103889')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1bbf2f81-4c20-44aa-a04d-1b8ad6103889 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1bbf2f81-4c20-44aa-a04d-1b8ad6103889');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f5f9b771-12e2-46a0-8e62-dba6b8b25124\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5f9b771-12e2-46a0-8e62-dba6b8b25124')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f5f9b771-12e2-46a0-8e62-dba6b8b25124 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 74681,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3740,\n        \"min\": 1,\n        \"max\": 13200,\n        \"num_unique_values\": 12447,\n        \"samples\": [\n          1616,\n          2660,\n          2335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"game\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Cyberpunk2077\",\n          \"Microsoft\",\n          \"TomClancysRainbowSix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Neutral\",\n          \"Irrelevant\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 69488,\n        \"samples\": [\n          \"Priestahh caught Clayster at abezy apathy\",\n          \"'Cyberpunk Christmas' Is Apparently Delayed By.tt/2FYMGr7\",\n          \"dont buy this please\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0xt2HoR-bqp",
        "outputId": "562af6ba-fc69-4465-fecd-578149b3ef96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74681, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOMw7GtUB0rA",
        "outputId": "a10285a1-61bc-4c82-d11c-971beb229755"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74681 entries, 0 to 74680\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         74681 non-null  int64 \n",
            " 1   game       74681 non-null  object\n",
            " 2   sentiment  74681 non-null  object\n",
            " 3   text       73995 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # mengatasi data yang hilang\n",
        "    if isinstance(text, float):  # Periksa apakah nilainya adalah float (bisa berupa NaN)\n",
        "        text = str(text)  # Ubah ke string jika perlu\n",
        "    # Mengubah teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "    # Menghilangkan karakter spesial, angka, dan tanda baca\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Menghapus ekstra spasi\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Terapkan preprocessing ke kolom 'text'\n",
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Encode label sentimen\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['sentiment'])\n",
        "\n",
        "# Pisahkan data menjadi train dan test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "# Ekstraksi fitur menggunakan TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Train set size: {X_train_tfidf.shape}\")\n",
        "print(f\"Test set size: {X_test_tfidf.shape}\")\n",
        "print(\"Label classes:\", le.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXm5qD1YDSlK",
        "outputId": "c293a593-0640-46ba-905c-6fcae79a3d56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: (59744, 5000)\n",
            "Test set size: (14937, 5000)\n",
            "Label classes: ['Irrelevant' 'Negative' 'Neutral' 'Positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#menggunkan Naive Bayes"
      ],
      "metadata": {
        "id": "WRQzrqLkFyBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Training model Naive Bayes\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluasi model\n",
        "predictions = model.predict(X_test_tfidf)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions, target_names=le.classes_))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZAjbbcnFxny",
        "outputId": "c4c62629-03b7-49cc-fa15-a746a0f3ded0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.75      0.34      0.47      2598\n",
            "    Negative       0.62      0.81      0.70      4509\n",
            "     Neutral       0.67      0.51      0.58      3664\n",
            "    Positive       0.61      0.74      0.67      4166\n",
            "\n",
            "    accuracy                           0.64     14937\n",
            "   macro avg       0.66      0.60      0.61     14937\n",
            "weighted avg       0.65      0.64      0.62     14937\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 879  721  289  709]\n",
            " [  64 3663  304  478]\n",
            " [ 141  858 1872  793]\n",
            " [  82  645  340 3099]]\n",
            "\n",
            "Accuracy Score: 0.6368748744727857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "# reducing data dengan PCA\n",
        "svd = TruncatedSVD(n_components=300, random_state=42)\n",
        "X_train_reduced = svd.fit_transform(X_train_tfidf)\n",
        "X_test_reduced = svd.transform(X_test_tfidf)\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, model_name, X_train_data, X_test_data): # Added X_train_data and X_test_data as parameters\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    if model_name == 'LinearSVC':  # Changed from 'Linear SVM'\n",
        "        X_train_data = X_train_reduced\n",
        "        X_test_data = X_test_reduced\n",
        "    else:\n",
        "        X_train_data = X_train_tfidf\n",
        "        X_test_data = X_test_tfidf\n",
        "    model.fit(X_train_data, y_train) # Changed to use X_train_data\n",
        "    predictions = model.predict(X_test_data) # Changed to use X_test_data\n",
        "    print(f\"\\n{model_name} - Classification Report:\\n\", classification_report(y_test, predictions, target_names=le.classes_))\n",
        "    print(f\"\\n{model_name} - Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "    print(f\"\\n{model_name} - Accuracy Score:\", accuracy_score(y_test, predictions))\n",
        "\n",
        "# Daftar model yang akan diuji\n",
        "models = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    # 'Support Vector Machine': SVC(kernel='linear', random_state=42)\n",
        "    'LinearSVC': LinearSVC(random_state=42)\n",
        "}\n",
        "\n",
        "# Melatih dan mengevaluasi setiap model\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'LinearSVC': # Changed from 'Linear SVM' to match the model dictionary key\n",
        "        # Gunakan data yang sudah direduksi untuk SVM\n",
        "        train_and_evaluate(model, model_name, X_train_reduced, X_test_reduced)\n",
        "    else:\n",
        "        # Gunakan data asli untuk model lainnya\n",
        "        train_and_evaluate(model, model_name, X_train_tfidf, X_test_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juVLQsLuHHa7",
        "outputId": "f7d7e0e2-a5a7-4298-8baa-4ef68154fa35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Naive Bayes...\n",
            "\n",
            "Naive Bayes - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.75      0.34      0.47      2598\n",
            "    Negative       0.62      0.81      0.70      4509\n",
            "     Neutral       0.67      0.51      0.58      3664\n",
            "    Positive       0.61      0.74      0.67      4166\n",
            "\n",
            "    accuracy                           0.64     14937\n",
            "   macro avg       0.66      0.60      0.61     14937\n",
            "weighted avg       0.65      0.64      0.62     14937\n",
            "\n",
            "\n",
            "Naive Bayes - Confusion Matrix:\n",
            " [[ 879  721  289  709]\n",
            " [  64 3663  304  478]\n",
            " [ 141  858 1872  793]\n",
            " [  82  645  340 3099]]\n",
            "\n",
            "Naive Bayes - Accuracy Score: 0.6368748744727857\n",
            "\n",
            "Training Logistic Regression...\n",
            "\n",
            "Logistic Regression - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.67      0.52      0.59      2598\n",
            "    Negative       0.72      0.78      0.75      4509\n",
            "     Neutral       0.63      0.64      0.64      3664\n",
            "    Positive       0.69      0.72      0.70      4166\n",
            "\n",
            "    accuracy                           0.68     14937\n",
            "   macro avg       0.68      0.67      0.67     14937\n",
            "weighted avg       0.68      0.68      0.68     14937\n",
            "\n",
            "\n",
            "Logistic Regression - Confusion Matrix:\n",
            " [[1363  392  360  483]\n",
            " [ 178 3514  461  356]\n",
            " [ 276  517 2336  535]\n",
            " [ 205  426  525 3010]]\n",
            "\n",
            "Logistic Regression - Accuracy Score: 0.6844078462877419\n",
            "\n",
            "Training LinearSVC...\n",
            "\n",
            "LinearSVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.49      0.24      0.32      2598\n",
            "    Negative       0.58      0.69      0.63      4509\n",
            "     Neutral       0.50      0.50      0.50      3664\n",
            "    Positive       0.57      0.63      0.59      4166\n",
            "\n",
            "    accuracy                           0.55     14937\n",
            "   macro avg       0.53      0.51      0.51     14937\n",
            "weighted avg       0.54      0.55      0.53     14937\n",
            "\n",
            "\n",
            "LinearSVC - Confusion Matrix:\n",
            " [[ 628  729  498  743]\n",
            " [ 178 3124  671  536]\n",
            " [ 281  839 1818  726]\n",
            " [ 183  695  678 2610]]\n",
            "\n",
            "LinearSVC - Accuracy Score: 0.5476333935863962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training SVM tanpa PCA\n",
        "print(\"\\nTraining SVM without PCA...\")\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "svm_predictions = svm_model.predict(X_test_tfidf)\n",
        "print(\"\\nSVM without PCA - Classification Report:\\n\", classification_report(y_test, svm_predictions, target_names=le.classes_))\n",
        "print(\"\\nSVM without PCA - Confusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n",
        "print(\"\\nSVM without PCA - Accuracy Score:\", accuracy_score(y_test, svm_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3poT_iZNRvk",
        "outputId": "b5d8bc8c-a29b-4c13-c624-183915fba6a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training SVM without PCA...\n",
            "\n",
            "SVM without PCA - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.69      0.58      0.63      2598\n",
            "    Negative       0.74      0.79      0.77      4509\n",
            "     Neutral       0.67      0.67      0.67      3664\n",
            "    Positive       0.71      0.73      0.72      4166\n",
            "\n",
            "    accuracy                           0.71     14937\n",
            "   macro avg       0.70      0.69      0.70     14937\n",
            "weighted avg       0.71      0.71      0.71     14937\n",
            "\n",
            "\n",
            "SVM without PCA - Confusion Matrix:\n",
            " [[1499  347  315  437]\n",
            " [ 204 3566  406  333]\n",
            " [ 260  481 2438  485]\n",
            " [ 222  411  474 3059]]\n",
            "\n",
            "SVM without PCA - Accuracy Score: 0.7071031666331927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training SVM tanpa PCA\n",
        "print(\"\\nTraining SVM without PCA...\")\n",
        "svm_model = LinearSVC(random_state=42)\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "svm_predictions = svm_model.predict(X_test_tfidf)\n",
        "print(\"\\nLinearSVC without PCA - Classification Report:\\n\", classification_report(y_test, svm_predictions, target_names=le.classes_))\n",
        "print(\"\\nLinearSVC without PCA - Confusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n",
        "print(\"\\nLinearSVC without PCA - Accuracy Score:\", accuracy_score(y_test, svm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufT5_UNyQ2_C",
        "outputId": "c4b20029-30fe-4343-cebd-8ba1f2cc0864"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training SVM without PCA...\n",
            "\n",
            "LinearSVC without PCA - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.71      0.59      0.64      2598\n",
            "    Negative       0.75      0.78      0.77      4509\n",
            "     Neutral       0.66      0.66      0.66      3664\n",
            "    Positive       0.70      0.74      0.72      4166\n",
            "\n",
            "    accuracy                           0.71     14937\n",
            "   macro avg       0.70      0.69      0.70     14937\n",
            "weighted avg       0.71      0.71      0.70     14937\n",
            "\n",
            "\n",
            "LinearSVC without PCA - Confusion Matrix:\n",
            " [[1520  319  324  435]\n",
            " [ 169 3538  429  373]\n",
            " [ 262  460 2420  522]\n",
            " [ 189  407  504 3066]]\n",
            "\n",
            "LinearSVC without PCA - Accuracy Score: 0.7058981053759121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import uniform\n",
        "# Tuning Hyperparameter untuk LinearSVC\n",
        "param_dist = {\n",
        "    'C': uniform(0.01, 10),\n",
        "    'penalty': ['l2'],  # 'l1' tidak didukung tanpa liblinear\n",
        "    'loss': ['hinge', 'squared_hinge']\n",
        "}\n",
        "\n",
        "svc = LinearSVC(random_state=42, max_iter=1000)\n",
        "random_search = RandomizedSearchCV(\n",
        "    svc,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nTuning LinearSVC with RandomizedSearchCV...\")\n",
        "random_search.fit(X_train_tfidf, y_train)\n",
        "print(\"\\nBest Parameters:\", random_search.best_params_)\n",
        "print(\"\\nBest Cross-Validation Score:\", random_search.best_score_)\n",
        "\n",
        "# Evaluasi dengan parameter terbaik\n",
        "best_svc = random_search.best_estimator_\n",
        "predictions = best_svc.predict(X_test_tfidf)\n",
        "print(\"\\nBest LinearSVC - Classification Report:\\n\", classification_report(y_test, predictions, target_names=le.classes_))\n",
        "print(\"\\nBest LinearSVC - Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "print(\"\\nBest LinearSVC - Accuracy Score:\", accuracy_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuRqE-tCUUnh",
        "outputId": "e6192b07-bafe-4a78-9912-017151bd892d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tuning LinearSVC with RandomizedSearchCV...\n",
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "\n",
            "Best Parameters: {'C': np.float64(9.74755518841459), 'loss': 'hinge', 'penalty': 'l2'}\n",
            "\n",
            "Best Cross-Validation Score: 0.697844119117175\n",
            "\n",
            "Best LinearSVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.65      0.61      0.63      2598\n",
            "    Negative       0.76      0.79      0.77      4509\n",
            "     Neutral       0.68      0.64      0.66      3664\n",
            "    Positive       0.71      0.73      0.72      4166\n",
            "\n",
            "    accuracy                           0.71     14937\n",
            "   macro avg       0.70      0.69      0.69     14937\n",
            "weighted avg       0.70      0.71      0.70     14937\n",
            "\n",
            "\n",
            "Best LinearSVC - Confusion Matrix:\n",
            " [[1585  307  305  401]\n",
            " [ 238 3551  366  354]\n",
            " [ 350  457 2350  507]\n",
            " [ 266  387  454 3059]]\n",
            "\n",
            "Best LinearSVC - Accuracy Score: 0.7059650532235389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch transformers scikit-learn pandas numpy\n",
        "!pip install --upgrade transformers\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bc8rJOgXQVO",
        "outputId": "ed8dbb49-9a6b-48db-9ab4-e10327ca4595"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "file_path = 'twitter_training_updeted.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, float):\n",
        "        text = str(text)\n",
        "    return text.lower()\n",
        "\n",
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {label: idx for idx, label in enumerate(df['sentiment'].unique())}\n",
        "df['label'] = df['sentiment'].map(label_mapping)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "# Load Tiny BERT model and tokenizer\n",
        "model_name = \"prajjwal1/bert-tiny\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_mapping))\n",
        "\n",
        "# Tokenize data\n",
        "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Create Torch datasets\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = SentimentDataset(train_encodings, y_train.tolist())\n",
        "test_dataset = SentimentDataset(test_encodings, y_test.tolist())\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_total_limit=1, # Only keep the best model after each epoch\n",
        "    eval_steps=100,  # Evaluate every 100 steps. Adjust as needed.\n",
        "    report_to=\"none\"  # Nonaktifkan wandb\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=label_mapping.keys()))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KoHW2CDeW2z5",
        "outputId": "0f76a28d-b5e4-434b-aece-f2d108a6d3e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11202' max='11202' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11202/11202 02:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.367300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.358400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.342300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.320400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.304800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.287800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.257000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.218900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.204100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.190700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.151900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.155500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.142000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.132800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.114300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.097300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.121400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.086800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.053000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>1.053800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.038200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.032700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>1.051700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>1.046400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>1.019700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.996000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.025800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>1.021100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.979300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.978700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.971600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.980500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.976300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.954000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.938900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.949700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.920900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.928200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.880800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.934400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.891400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.887800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.887700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.865000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.880600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.892400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.845200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.874800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.856200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.882700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.889100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.883000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.867600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.864700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.875800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.844400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.840900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.869600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.831300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.859200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.828500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.826300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.837200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.832000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.868600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.824600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.813800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.851400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.795300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.816000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.762500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.804500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.791500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.719800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.803100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.774600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.752700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.799400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.777700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.767900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.754700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.734200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.758700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.760500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.754500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.740500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.744300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.786400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.737800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.744300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.729400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.750100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.763100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.785300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.749400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.735100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.746000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.795000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.721400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.757300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.750100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.741600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.707500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.746600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.750400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.71      0.75      0.73      4166\n",
            "     Neutral       0.71      0.60      0.65      3664\n",
            "    Negative       0.76      0.81      0.79      4509\n",
            "  Irrelevant       0.62      0.62      0.62      2598\n",
            "\n",
            "    accuracy                           0.71     14937\n",
            "   macro avg       0.70      0.70      0.70     14937\n",
            "weighted avg       0.71      0.71      0.71     14937\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3142  343  412  269]\n",
            " [ 496 2207  474  487]\n",
            " [ 368  236 3673  232]\n",
            " [ 412  303  279 1604]]\n",
            "\n",
            "Accuracy Score: 0.7113878288813015\n"
          ]
        }
      ]
    }
  ]
}